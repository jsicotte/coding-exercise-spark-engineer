{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c0f97947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{to_date, to_timestamp}\n",
       "receipts: org.apache.spark.sql.DataFrame = [RECEIPT_ID: string, STORE_NAME: string ... 14 more fields]\n",
       "items: org.apache.spark.sql.DataFrame = [REWARDS_RECEIPT_ID: string, ITEM_INDEX: int ... 11 more fields]\n"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{to_date, to_timestamp}\n",
    "import org.apache.spark.sql.functions.{regexp_replace}\n",
    "import org.apache.spark.sql.functions.{year}\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.functions.{rank}\n",
    "\n",
    "val receipts = spark.read\n",
    "                  .option(\"header\", \"true\")\n",
    "                  .option(\"inferschema\", \"true\")\n",
    "                  .csv(\"/home/jovyan/work/rewards_receipts_lat_v3.csv\")\n",
    "                  .withColumn(\"RECEIPT_PURCHASE_DATE\", to_timestamp(col(\"RECEIPT_PURCHASE_DATE\"), \"yyyy-MM-dd HH:mm:ss.SSS\"))\n",
    "\n",
    "val items = spark.read\n",
    "                  .option(\"header\", \"true\")\n",
    "                  .option(\"inferschema\", \"true\")\n",
    "                  .csv(\"/home/jovyan/work/rewards_receipts_item_lat_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "56dc737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+-----------+-----------+---------+------------+------------+--------------------+--------------------+---------------------+-------------+------------------+--------------------+--------------------+---------------+\n",
      "|          RECEIPT_ID|STORE_NAME|       STORE_ADDRESS| STORE_CITY|STORE_STATE|STORE_ZIP| STORE_PHONE|STORE_NUMBER|             USER_ID|           SCAN_DATE|RECEIPT_PURCHASE_DATE|RECEIPT_TOTAL|RECEIPT_ITEM_COUNT| CONSUMER_USER_AGENT|         MODIFY_DATE|DIGITAL_RECEIPT|\n",
      "+--------------------+----------+--------------------+-----------+-----------+---------+------------+------------+--------------------+--------------------+---------------------+-------------+------------------+--------------------+--------------------+---------------+\n",
      "|5fe8a743f513262b9...|     GIANT|5463 Wisconsin Av...|Chevy Chase|         MD|    20815|240-497-6100|         312|94048e4f27ef9fdc9...|2019-05-02 18:47:...|  2019-05-01 21:52:00|        39.84|                19|Fetch Rewards/2.1...|2019-05-02 18:48:...|          false|\n",
      "|5ffc9647bbe9d1880...|    KROGER|    6001 Cumming Hwy| Sugar Hill|         GA|    30518|678-546-2148|         687|c69584c843eb91bbc...|2019-06-09 20:24:...|  2019-06-09 16:08:00|        88.43|                26|Fetch Rewards/2.1...|2019-06-09 20:25:...|          false|\n",
      "+--------------------+----------+--------------------+-----------+-----------+---------+------------+------------+--------------------+--------------------+---------------------+-------------+------------------+--------------------+--------------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "receipts.show(2)\n",
    "receipts.createOrReplaceTempView(\"receipts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc7bcec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+------------+------------+--------+----------+----------------+------+-------------+--------------+--------------------+--------------------+\n",
      "|  REWARDS_RECEIPT_ID|ITEM_INDEX| RECEIPT_DESCRIPTION|BARCODE_ORIG|     BARCODE|QUANTITY|ITEM_PRICE|DISCOUNTED_PRICE|WEIGHT|REWARDS_GROUP|         BRAND|            CATEGORY|        PRODUCT_NAME|\n",
      "+--------------------+----------+--------------------+------------+------------+--------+----------+----------------+------+-------------+--------------+--------------------+--------------------+\n",
      "|027a0c049debc76cb...|        26|Sb Basil, Garlic ...|        null|        null|       1|      1.09|            1.09|  null|         null|            Sb|Grocery|Canned & ...|Sb Basil, Garlic ...|\n",
      "|05ea1810aec3a5567...|         9|Back to Nature Cr...|819898010288|819898010288|       1|       1.0|             1.0|  null|         null|Back to Nature|Grocery|Snacks|Cr...|Back to Nature Sp...|\n",
      "+--------------------+----------+--------------------+------------+------------+--------+----------+----------------+------+-------------+--------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items.show(2)\n",
    "items.createOrReplaceTempView(\"items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e582c2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joined_df: org.apache.spark.sql.DataFrame = [RECEIPT_ID: string, STORE_NAME: string ... 27 more fields]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val joined_df = receipts.join(items, receipts(\"RECEIPT_ID\") === items(\"REWARDS_RECEIPT_ID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1b98681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res10: Long = 14066\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4223e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+-----------+\n",
      "|            store_id|RECEIPT_PURCHASE_DATE|daily_total|\n",
      "+--------------------+---------------------+-----------+\n",
      "|36 East West Newe...|           2019-11-04|     409.17|\n",
      "|8101 W Judge Pere...|           2019-04-12|     207.45|\n",
      "|  533 Middle Neck Rd|           2019-06-24|    1886.03|\n",
      "|8101 W Judge Pere...|           2019-05-11|     315.37|\n",
      "|   2425 Longfibre Rd|           2019-09-10|     456.74|\n",
      "|1430 NW Garden Va...|           2019-03-31|     758.96|\n",
      "|      820 Market St.|           2020-05-03|      768.6|\n",
      "|    7250 Pacific Ave|           2019-08-01|     512.88|\n",
      "|      11 Main Street|           2019-12-17|      589.6|\n",
      "|  1457 FAIRFIELD AVE|           2020-06-11|     555.27|\n",
      "|       111 104th Ave|           2020-01-31|     406.18|\n",
      "+--------------------+---------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// In some cases a store_number or address can identify a store. There are also instances\n",
    "// where both of these fields are null but there is a store_phone.\n",
    "// I have also noticed garbage values in store_city and store_state, so all columns are suspect.\n",
    "// There does not seem a way to use store_phone to fill in missing data.\n",
    "\n",
    "// total dollar amount per store by date\n",
    "spark.sql(\"\"\"\n",
    "    with filtered_stores as (\n",
    "        select COALESCE(store_address, store_number, store_phone) as store_id, store_name, RECEIPT_TOTAL, RECEIPT_PURCHASE_DATE\n",
    "        from receipts as r\n",
    "        where not (store_address is null and store_number is null and store_phone is null)\n",
    "    ),\n",
    "    sums as (\n",
    "        select store_id, store_name, sum(RECEIPT_TOTAL) as total from filtered_stores group by store_id, store_name\n",
    "    ),\n",
    "    top_ten as (\n",
    "        select store_id from sums order by total desc limit 10\n",
    "    )\n",
    "    select f.store_id, date(RECEIPT_PURCHASE_DATE), sum(RECEIPT_TOTAL) as daily_total from filtered_stores f\n",
    "    join top_ten t on f.store_id = t.store_id\n",
    "    group by 1, 2\n",
    "    \n",
    "    \n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ab6e5cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     887|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with result as (\n",
    "        select STORE_ADDRESS from receipts group by 1\n",
    "    )\n",
    "    select count(*) from result\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6d66a05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+-------------+-----+----+\n",
      "|   store_id|           last_elm|purchase_date|count|rank|\n",
      "+-----------+-------------------+-------------+-----+----+\n",
      "|1 Kent Road|             Yogurt|   2019-08-04|    4|   1|\n",
      "|1 Kent Road|   Latin Seasonings|   2019-08-04|    4|   1|\n",
      "|1 Kent Road|  Cottage & Ricotta|   2019-08-04|    4|   1|\n",
      "|1 Kent Road|            Berries|   2019-08-04|    4|   1|\n",
      "|1 Kent Road|       Buns & Rolls|   2019-08-04|    3|   5|\n",
      "|1 Kent Road|            Poultry|   2019-08-04|    3|   5|\n",
      "|1 Kent Road|     Meat & Seafood|   2019-08-04|    3|   5|\n",
      "|1 Kent Road|     Poultry Pieces|   2019-08-04|    2|   8|\n",
      "|1 Kent Road|             Salami|   2019-08-04|    2|   8|\n",
      "|1 Kent Road|            Produce|   2019-08-04|    2|   8|\n",
      "|1 Kent Road|         Sandwiches|   2019-08-04|    2|   8|\n",
      "|1 Kent Road| Salads-Prepackaged|   2019-08-04|    2|   8|\n",
      "|1 Kent Road|     Chips - Potato|   2019-08-04|    2|   8|\n",
      "|1 Kent Road|              Dairy|   2019-08-04|    2|   8|\n",
      "|1 Kent Road|           Iced Tea|   2019-08-04|    2|   8|\n",
      "|1 Kent Road|           Lemonade|   2019-08-04|    2|   8|\n",
      "|1 Kent Road|     G136 ICED TEAS|   2019-08-04|    2|   8|\n",
      "|1 Kent Road|               Eggs|   2019-08-04|    2|   8|\n",
      "|1 Kent Road|        Nectarines |   2019-08-04|    1|  19|\n",
      "|1 Kent Road|    English Muffins|   2019-08-04|    1|  19|\n",
      "|1 Kent Road|   Fresh Vegetables|   2019-08-04|    1|  19|\n",
      "|1 Kent Road|            Popcorn|   2019-08-04|    1|  19|\n",
      "|1 Kent Road|Bread - Wheat/Grain|   2019-08-04|    1|  19|\n",
      "|1 Kent Road|  Tortillas & Tacos|   2019-08-04|    1|  19|\n",
      "|1 Kent Road|       Flour & Meal|   2019-08-04|    1|  19|\n",
      "|1 Kent Road|             Bagels|   2019-08-04|    1|  19|\n",
      "|1 Kent Road|            Bananas|   2019-08-04|    1|  19|\n",
      "+-----------+-------------------+-------------+-----+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.Window\n",
       "import org.apache.spark.sql.functions.rank\n",
       "windowSpec: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@2be91a3c\n"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// category popularity by store and day\n",
    "val windowSpec = Window.partitionBy(\"store_id\", \"purchase_date\").orderBy(col(\"count\").desc)\n",
    "\n",
    "spark\n",
    "    .sql(\"\"\"\n",
    "        with filtered_receipts as (\n",
    "            select COALESCE(store_address, store_number, store_phone) as store_id,RECEIPT_ID, store_name, RECEIPT_TOTAL, date(RECEIPT_PURCHASE_DATE) as purchase_date\n",
    "            from receipts as r\n",
    "            where not (store_address is null and store_number is null and store_phone is null)\n",
    "        )\n",
    "        select * from filtered_receipts r\n",
    "        join items i on r.RECEIPT_ID = i.REWARDS_RECEIPT_ID\n",
    "    \"\"\")\n",
    "    .withColumn(\"category_array\", split(col(\"CATEGORY\"), \"\\\\|\"))\n",
    "    .withColumn(\"last_elm\", element_at(col(\"category_array\"), -1))\n",
    "    .select(col(\"store_id\"), col(\"last_elm\"), col(\"purchase_date\"))\n",
    "    .filter(\"last_elm is not null\")\n",
    "    .groupBy(\"store_id\", \"last_elm\", \"purchase_date\")\n",
    "    .count()\n",
    "    .withColumn(\"rank\", rank().over(windowSpec))\n",
    "    .orderBy(col(\"store_id\"), col(\"purchase_date\"), col(\"rank\").asc)\n",
    "    .show(50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1703b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-----+\n",
      "|year|       device|count|\n",
      "+----+-------------+-----+\n",
      "|2020|   iPhone12,1|   49|\n",
      "|2020|iPhone 8 Plus|   43|\n",
      "|2019|iPhone 7 Plus|   40|\n",
      "|2020|    iPhone XR|   39|\n",
      "|2019|     iPhone 7|   38|\n",
      "|2019|iPhone 8 Plus|   35|\n",
      "|2019|     iPhone 8|   31|\n",
      "|2019|    iPhone XR|   27|\n",
      "|2020|     iPhone 7|   27|\n",
      "|2020|iPhone 7 Plus|   24|\n",
      "|2020|     iPhone X|   22|\n",
      "|2020|     iPhone 8|   22|\n",
      "|2020|    iPhone 6s|   22|\n",
      "|2019|     iPhone X|   21|\n",
      "|2019|    iPhone 6s|   21|\n",
      "|2020|iPhone Xs Max|   19|\n",
      "|2019|iPhone Xs Max|   18|\n",
      "|2019|     SM-G950U|   15|\n",
      "|2020|     SM-G950U|   15|\n",
      "|2019|     iPhone 6|   13|\n",
      "+----+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.regexp_replace\n",
       "import org.apache.spark.sql.functions.year\n"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// device count by year\n",
    "\n",
    "spark.sql(\"select distinct RECEIPT_PURCHASE_DATE, CONSUMER_USER_AGENT from receipts\")\n",
    ".withColumn(\"device\", regexp_replace(col(\"CONSUMER_USER_AGENT\"), \"Fetch.*\\\\(\", \"\"))\n",
    ".withColumn(\"device\", regexp_replace(col(\"device\"), \";.*\", \"\"))\n",
    ".withColumn(\"year\", year(col(\"RECEIPT_PURCHASE_DATE\")))\n",
    ".groupBy(\"year\", \"device\").count()\n",
    ".orderBy(col(\"count\").desc)\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2bc34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
